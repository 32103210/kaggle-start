{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    train = pd.read_csv('../input/train.csv')\n",
    "    test = pd.read_csv('../input/test.csv')\n",
    "    print(\"train shape:{}\\ntest shape:{}\".format(train.shape, test.shape))\n",
    "    \n",
    "    train_df = train.drop(['label'], axis=1)\n",
    "    label = pd.get_dummies(train['label'])\n",
    "    #train_df = train_df/255.0\n",
    "    #test = test/255.0\n",
    "    train_df = train_df.applymap(lambda x: x/255).astype(np.float32)\n",
    "    test = test.applymap(lambda x: x/255).astype(np.float32)\n",
    "    \n",
    "    # Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\n",
    "    train_df = train_df.values.reshape(-1,28,28,1)\n",
    "    test = test.values.reshape(-1,28,28,1)\n",
    "    \n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(train_df, label, test_size=0.2, random_state=2017)\n",
    "    print(\"x_train shape:\"+str(x_train.shape))\n",
    "    print(\"x_valid shape:\"+str(x_valid.shape))\n",
    "    \n",
    "    return x_train, y_train, x_valid, y_valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:(42000, 785)\n",
      "test shape:(28000, 784)\n",
      "x_train shape:(33600, 28, 28, 1)\n",
      "x_valid shape:(8400, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_valid, y_valid, x_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/50\n",
      "33600/33600 [==============================] - 7s 223us/step - loss: 0.8542 - acc: 0.7163 - val_loss: 0.1859 - val_acc: 0.9449\n",
      "Epoch 2/50\n",
      "33600/33600 [==============================] - 7s 201us/step - loss: 0.3043 - acc: 0.9159 - val_loss: 0.1204 - val_acc: 0.9640\n",
      "Epoch 3/50\n",
      "33600/33600 [==============================] - 7s 206us/step - loss: 0.2304 - acc: 0.9378 - val_loss: 0.1020 - val_acc: 0.9674\n",
      "Epoch 4/50\n",
      "33600/33600 [==============================] - 7s 210us/step - loss: 0.1956 - acc: 0.9476 - val_loss: 0.0855 - val_acc: 0.9745\n",
      "Epoch 5/50\n",
      "33600/33600 [==============================] - 7s 222us/step - loss: 0.1703 - acc: 0.9526 - val_loss: 0.0767 - val_acc: 0.9751\n",
      "Epoch 6/50\n",
      "33600/33600 [==============================] - 8s 229us/step - loss: 0.1504 - acc: 0.9606 - val_loss: 0.0647 - val_acc: 0.9796\n",
      "Epoch 7/50\n",
      "33600/33600 [==============================] - 8s 232us/step - loss: 0.1429 - acc: 0.9607 - val_loss: 0.0671 - val_acc: 0.9806\n",
      "Epoch 8/50\n",
      "33600/33600 [==============================] - 7s 214us/step - loss: 0.1331 - acc: 0.9648 - val_loss: 0.0599 - val_acc: 0.9807\n",
      "Epoch 9/50\n",
      "33600/33600 [==============================] - 7s 212us/step - loss: 0.1230 - acc: 0.9669 - val_loss: 0.0608 - val_acc: 0.9820\n",
      "Epoch 10/50\n",
      "33600/33600 [==============================] - 7s 210us/step - loss: 0.1173 - acc: 0.9684 - val_loss: 0.0546 - val_acc: 0.9843\n",
      "Epoch 11/50\n",
      "33600/33600 [==============================] - 8s 224us/step - loss: 0.1090 - acc: 0.9704 - val_loss: 0.0637 - val_acc: 0.9826\n",
      "Epoch 12/50\n",
      "33600/33600 [==============================] - 7s 206us/step - loss: 0.1061 - acc: 0.9706 - val_loss: 0.0516 - val_acc: 0.9842\n",
      "Epoch 13/50\n",
      "33600/33600 [==============================] - 7s 209us/step - loss: 0.1018 - acc: 0.9718 - val_loss: 0.0472 - val_acc: 0.9865\n",
      "Epoch 14/50\n",
      "33600/33600 [==============================] - 7s 212us/step - loss: 0.1003 - acc: 0.9728 - val_loss: 0.0512 - val_acc: 0.9835\n",
      "Epoch 15/50\n",
      "33600/33600 [==============================] - 7s 208us/step - loss: 0.0978 - acc: 0.9738 - val_loss: 0.0512 - val_acc: 0.9850\n",
      "Epoch 16/50\n",
      "33600/33600 [==============================] - 7s 205us/step - loss: 0.0954 - acc: 0.9737 - val_loss: 0.0521 - val_acc: 0.9843\n",
      "Epoch 17/50\n",
      "33600/33600 [==============================] - 7s 206us/step - loss: 0.0956 - acc: 0.9742 - val_loss: 0.0454 - val_acc: 0.9877\n",
      "Epoch 18/50\n",
      "33600/33600 [==============================] - 7s 205us/step - loss: 0.0890 - acc: 0.9751 - val_loss: 0.0494 - val_acc: 0.9864\n",
      "Epoch 19/50\n",
      "33600/33600 [==============================] - 7s 205us/step - loss: 0.0844 - acc: 0.9771 - val_loss: 0.0460 - val_acc: 0.9861\n",
      "Epoch 20/50\n",
      "33600/33600 [==============================] - 7s 203us/step - loss: 0.0880 - acc: 0.9768 - val_loss: 0.0528 - val_acc: 0.9844\n",
      "Epoch 21/50\n",
      "33600/33600 [==============================] - 7s 204us/step - loss: 0.0819 - acc: 0.9780 - val_loss: 0.0465 - val_acc: 0.9865\n",
      "Epoch 22/50\n",
      "33600/33600 [==============================] - 7s 204us/step - loss: 0.0811 - acc: 0.9787 - val_loss: 0.0469 - val_acc: 0.9869\n",
      "Epoch 23/50\n",
      "33600/33600 [==============================] - 7s 206us/step - loss: 0.0806 - acc: 0.9771 - val_loss: 0.0459 - val_acc: 0.9880\n",
      "Epoch 24/50\n",
      "33600/33600 [==============================] - 7s 206us/step - loss: 0.0791 - acc: 0.9768 - val_loss: 0.0456 - val_acc: 0.9877\n",
      "Epoch 25/50\n",
      "33600/33600 [==============================] - 7s 205us/step - loss: 0.0755 - acc: 0.9788 - val_loss: 0.0417 - val_acc: 0.9871\n",
      "Epoch 26/50\n",
      "33600/33600 [==============================] - 7s 207us/step - loss: 0.0742 - acc: 0.9785 - val_loss: 0.0384 - val_acc: 0.9902\n",
      "Epoch 27/50\n",
      "33600/33600 [==============================] - 7s 205us/step - loss: 0.0736 - acc: 0.9804 - val_loss: 0.0476 - val_acc: 0.9881\n",
      "Epoch 28/50\n",
      "33600/33600 [==============================] - 7s 205us/step - loss: 0.0753 - acc: 0.9786 - val_loss: 0.0446 - val_acc: 0.9881\n",
      "Epoch 29/50\n",
      "33600/33600 [==============================] - 7s 205us/step - loss: 0.0730 - acc: 0.9798 - val_loss: 0.0454 - val_acc: 0.9877\n",
      "Epoch 30/50\n",
      "33600/33600 [==============================] - 7s 204us/step - loss: 0.0767 - acc: 0.9784 - val_loss: 0.0409 - val_acc: 0.9880\n",
      "Epoch 31/50\n",
      "33600/33600 [==============================] - 7s 223us/step - loss: 0.0672 - acc: 0.9807 - val_loss: 0.0450 - val_acc: 0.9879\n",
      "Epoch 32/50\n",
      "33600/33600 [==============================] - 7s 214us/step - loss: 0.0681 - acc: 0.9799 - val_loss: 0.0421 - val_acc: 0.9883\n",
      "Epoch 33/50\n",
      "33600/33600 [==============================] - 7s 222us/step - loss: 0.0682 - acc: 0.9805 - val_loss: 0.0439 - val_acc: 0.9886\n",
      "Epoch 34/50\n",
      "33600/33600 [==============================] - 8s 229us/step - loss: 0.0686 - acc: 0.9807 - val_loss: 0.0437 - val_acc: 0.9898\n",
      "Epoch 35/50\n",
      "33600/33600 [==============================] - 8s 223us/step - loss: 0.0655 - acc: 0.9815 - val_loss: 0.0478 - val_acc: 0.9895\n",
      "Epoch 36/50\n",
      "33600/33600 [==============================] - 8s 227us/step - loss: 0.0633 - acc: 0.9815 - val_loss: 0.0397 - val_acc: 0.9905\n",
      "Epoch 37/50\n",
      "33600/33600 [==============================] - 7s 219us/step - loss: 0.0665 - acc: 0.9812 - val_loss: 0.0452 - val_acc: 0.9877\n",
      "Epoch 38/50\n",
      "33600/33600 [==============================] - 7s 212us/step - loss: 0.0634 - acc: 0.9813 - val_loss: 0.0438 - val_acc: 0.9877\n",
      "Epoch 39/50\n",
      "33600/33600 [==============================] - 7s 209us/step - loss: 0.0612 - acc: 0.9830 - val_loss: 0.0456 - val_acc: 0.9874\n",
      "Epoch 40/50\n",
      "33600/33600 [==============================] - 7s 212us/step - loss: 0.0656 - acc: 0.9813 - val_loss: 0.0477 - val_acc: 0.9881\n",
      "Epoch 41/50\n",
      "33600/33600 [==============================] - 7s 210us/step - loss: 0.0610 - acc: 0.9824 - val_loss: 0.0450 - val_acc: 0.9882\n",
      "Epoch 42/50\n",
      "33600/33600 [==============================] - 7s 212us/step - loss: 0.0618 - acc: 0.9819 - val_loss: 0.0446 - val_acc: 0.9889\n",
      "Epoch 43/50\n",
      "33600/33600 [==============================] - 7s 207us/step - loss: 0.0595 - acc: 0.9824 - val_loss: 0.0481 - val_acc: 0.9882\n",
      "Epoch 44/50\n",
      "33600/33600 [==============================] - 7s 205us/step - loss: 0.0605 - acc: 0.9825 - val_loss: 0.0407 - val_acc: 0.9886\n",
      "Epoch 45/50\n",
      "33600/33600 [==============================] - 7s 208us/step - loss: 0.0581 - acc: 0.9837 - val_loss: 0.0405 - val_acc: 0.9898\n",
      "Epoch 46/50\n",
      "33600/33600 [==============================] - 7s 210us/step - loss: 0.0594 - acc: 0.9826 - val_loss: 0.0422 - val_acc: 0.9894\n",
      "Epoch 47/50\n",
      "33600/33600 [==============================] - 7s 208us/step - loss: 0.0627 - acc: 0.9821 - val_loss: 0.0508 - val_acc: 0.9858\n",
      "Epoch 48/50\n",
      "33600/33600 [==============================] - 7s 212us/step - loss: 0.0567 - acc: 0.9836 - val_loss: 0.0451 - val_acc: 0.9896\n",
      "Epoch 49/50\n",
      "33600/33600 [==============================] - 7s 209us/step - loss: 0.0612 - acc: 0.9829 - val_loss: 0.0424 - val_acc: 0.9893\n",
      "Epoch 50/50\n",
      "33600/33600 [==============================] - 7s 221us/step - loss: 0.0571 - acc: 0.9835 - val_loss: 0.0373 - val_acc: 0.9900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f652a0469e8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 牛逼的Sequential类可以让我们灵活地插入不同的神经网络层\n",
    "model = Sequential()\n",
    "\n",
    "# 加上一个2D卷积层， 32个输出（也就是卷积通道），激活函数选用relu，\n",
    "# 卷积核的窗口选用3*3像素窗口\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "# 池化层是2*2像素的\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# 对于池化层的输出，采用0.35概率的Dropout\n",
    "model.add(Dropout(0.35))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "# 池化层是2*2像素的\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# 对于池化层的输出，采用0.35概率的Dropout\n",
    "model.add(Dropout(0.35))\n",
    "\n",
    "# 展平所有像素，比如[28*28] -> [784]\n",
    "\n",
    "model.add(Flatten())\n",
    "# 对所有像素使用全连接层，输出为128，激活函数选用relu\n",
    "model.add(Dense(256, activation='relu'))\n",
    "# 对所有像素使用全连接层，输出为64，激活函数选用relu\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# 对输入采用0.5概率的Dropout\n",
    "model.add(Dropout(0.5))\n",
    "# 对刚才Dropout的输出采用softmax激活函数，得到最后结果0-9\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-3), metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=50, batch_size=64, verbose=1, validation_data=(x_valid, y_valid))\n",
    "\n",
    "# loss: 0.0293 - acc: 0.9915 - val_loss: 0.0323 - val_acc: 0.9925\n",
    "# LB -> 99.14%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# predict results\n",
    "results = model.predict(x_test)\n",
    "\n",
    "# select the indix with the maximum probability\n",
    "results = np.argmax(results,axis = 1)\n",
    "\n",
    "submit_df= pd.read_csv('../input/sample_submission.csv')\n",
    "submit_df.Label = results\n",
    "filename = \"../sub/{}.scv\".format(datetime.now().strftime('%Y%m%d_%H_%M'))\n",
    "submit_df.to_csv(filename,index=None,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
